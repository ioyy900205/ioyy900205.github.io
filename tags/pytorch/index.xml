<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PyTorch on 亮的笔记</title>
    <link>https://ioyy900205.github.io/tags/pytorch/</link>
    <description>Recent content in PyTorch on 亮的笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 16 Dec 2021 16:03:44 +0800</lastBuildDate><atom:link href="https://ioyy900205.github.io/tags/pytorch/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>49-字节残差unet的思考</title>
      <link>https://ioyy900205.github.io/post/2021-12-16-%E5%AD%97%E8%8A%82%E6%AE%8B%E5%B7%AEunet%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</link>
      <pubDate>Thu, 16 Dec 2021 16:03:44 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-12-16-%E5%AD%97%E8%8A%82%E6%AE%8B%E5%B7%AEunet%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</guid>
      <description>1. 无需LSTM结构 2. 无需将网络的 freq_bins 维度压缩至1. 3. 数据归一化的方式 4. 在融合了之后还进行了信息整理 5. 将频带切分 堆叠 送入网络  1. 无需LSTM结构 中间做信息处理的部分是block7a-block7d
每个block都有4个残差conv块
每个残差conv块有2层卷积
(x_center, _) = self.conv_block7a(x6_pool) # (bs, 384, T / 32, F / 64) (x_center, _) = self.conv_block7b(x_center) # (bs, 384, T / 32, F / 64) (x_center, _) = self.conv_block7c(x_center) # (bs, 384, T / 32, F / 64) (x_center, _) = self.conv_block7d(x_center) # (bs, 384, T / 32, F / 64) 2.</description>
    </item>
    
    <item>
      <title>48-python自动化(1)</title>
      <link>https://ioyy900205.github.io/post/2021-12-15-48-python%E8%87%AA%E5%8A%A8%E5%8C%961/</link>
      <pubDate>Wed, 15 Dec 2021 13:58:12 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-12-15-48-python%E8%87%AA%E5%8A%A8%E5%8C%961/</guid>
      <description>方便结果记录
 @TOC
1. 获取文件名 import pathlib pathlib.Path(__file__).stem 可以拿到运行xxx.py 的 xxx。简单来说是获取文件的名字
 参考资料</description>
    </item>
    
    <item>
      <title>Pytorch Lightning的调试bug</title>
      <link>https://ioyy900205.github.io/post/2021-12-14-lightning%E5%A4%AA%E5%9D%91%E4%BA%861/</link>
      <pubDate>Tue, 14 Dec 2021 14:13:16 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-12-14-lightning%E5%A4%AA%E5%9D%91%E4%BA%861/</guid>
      <description>一些非常奇怪的问题
 @TOC
DeadLock detected from rank: 0 这真的是个头疼的问题。
这个问题与模型参数的保存有关。我还没有发现比较好的解决办法。
网上查的解决办法是在ModelCheckpoint中设置save_weights_only=True 感觉不完美
在我的实践中，即使设置了，也不起作用。这就头疼了。。 经过1天时间研究我找到了一个比较合适的方法，逐步发现了问题：
解决方法： 找到 torch_lightning.utilities.cloud_io.py 定位到最后torch.save处
加入一行代码: checkpoint.pop(&amp;lsquo;hyper_parameters&amp;rsquo;)
备注： checkopint字典的k,v有 1.epoch 2.global_step 3.pytorch-lightning_version 4.state_dict 5.hparams_name 6.hyper_parameters
 参考资料
1</description>
    </item>
    
    <item>
      <title>45-PyTorch在imagenet上的推理验证</title>
      <link>https://ioyy900205.github.io/post/2021-08-18-45-pytorch%E5%9C%A8imagenet%E4%B8%8A%E7%9A%84%E6%8E%A8%E7%90%86%E9%AA%8C%E8%AF%81/</link>
      <pubDate>Wed, 18 Aug 2021 10:11:35 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-08-18-45-pytorch%E5%9C%A8imagenet%E4%B8%8A%E7%9A%84%E6%8E%A8%E7%90%86%E9%AA%8C%E8%AF%81/</guid>
      <description>给出在imagenet上的推理验证代码
这里有一个小意外，之前的NCNN和ONNX都是在这个框架上实现的。但是实现pytorch版本的时候，却始终显示结果不对。
检查问题之后，发现是model.eval()没有写。
经查： Batch Normalization 和 Dropout 方法模式不同。BN不会取平均，而是用训练好的值。 Dropout也不会有作用，这个是在训练时防止过拟合用的。
 @TOC
代码 &amp;#39;&amp;#39;&amp;#39; Date: 2021-08-10 14:12:17 LastEditors: Liuliang LastEditTime: 2021-08-17 18:16:08 Description: onnx在imagenet上的推理验证 &amp;#39;&amp;#39;&amp;#39; import argparse import os import random import shutil import time import warnings from Average_ import AverageMeter from Progress_ import ProgressMeter import torch import torch.nn as nn import torch.nn.parallel import torch.backends.cudnn as cudnn import torch.distributed as dist import torch.optim import torch.multiprocessing as mp import torch.utils.data import torch.</description>
    </item>
    
    <item>
      <title>37--如何写模型（二）</title>
      <link>https://ioyy900205.github.io/post/2021-07-09-37%E5%A6%82%E4%BD%95%E5%86%99%E6%A8%A1%E5%9E%8B%E4%BA%8C/</link>
      <pubDate>Fri, 09 Jul 2021 11:00:21 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-07-09-37%E5%A6%82%E4%BD%95%E5%86%99%E6%A8%A1%E5%9E%8B%E4%BA%8C/</guid>
      <description>如何写模型（二）
上次的核心是make_layer,通过返回sequential（）这种方法能够在该层中实现自动化操作。
这次希望能够实现多尺度架构的设计。
 @TOC
标题  参考资料</description>
    </item>
    
    <item>
      <title>36——如何写模型（一）</title>
      <link>https://ioyy900205.github.io/post/2021-07-08-36%E5%A6%82%E4%BD%95%E5%86%99%E6%A8%A1%E5%9E%8B%E4%B8%80/</link>
      <pubDate>Thu, 08 Jul 2021 17:43:31 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-07-08-36%E5%A6%82%E4%BD%95%E5%86%99%E6%A8%A1%E5%9E%8B%E4%B8%80/</guid>
      <description>如何写模型（一） 以ResNet为例
 @TOC
1. ResNet的构建 以ResNet为例，forward函数中，是前向传播过程，也是计算的核心内容。
def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) if self.include_top: x = self.avgpool(x) x = torch.flatten(x, 1) x = self.fc(x) return x 这里conv1、bn1、relu、maxpool、avgpool、fc都已经在__init__内很直观的定义好了。
问题就在于layer1-4的构建。那么我们以Restnet50为例，中间4个层每个block都要重复[3, 4, 6, 3]这么多次。e.g.第一层3次, 第二层4次，第三层6次，第四层3次。
那么可以看一下self.layer1-4是如何定义的。
self.layer1 = self._make_layer(block, 64, blocks_num[0]) self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2) self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2) self.</description>
    </item>
    
    <item>
      <title>34——List中三个点是什么</title>
      <link>https://ioyy900205.github.io/post/2021-07-05-34list%E4%B8%AD%E7%9A%84%E4%B8%89%E4%B8%AA%E7%82%B9/</link>
      <pubDate>Mon, 05 Jul 2021 09:10:42 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-07-05-34list%E4%B8%AD%E7%9A%84%E4%B8%89%E4%B8%AA%E7%82%B9/</guid>
      <description>a[&amp;hellip;]代表什么
 @TOC
1. 初始化一个a import random import numpy as np a = np.arange(25).reshape((5,5)) print(a) print(a.shape) 显示
[[ 0 1 2 3 4] [ 5 6 7 8 9] [10 11 12 13 14] [15 16 17 18 19] [20 21 22 23 24]] (5, 5) 2. 解释 2.1. 这个符号省略了所有的:,:,: c = a[...] print(&amp;#39;---------------------------------&amp;#39;) print(c) print(c.shape) 3. 实例 3.1. &amp;hellip;,None import random import numpy as np a = np.arange(25).reshape((5,5)) print(a) print(a.</description>
    </item>
    
    <item>
      <title>33——BCELoss和BCELosswithlogic</title>
      <link>https://ioyy900205.github.io/post/2021-07-03-33torch.nn.bceloss%E5%92%8Cbcelosswithlogic/</link>
      <pubDate>Sat, 03 Jul 2021 18:19:19 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-07-03-33torch.nn.bceloss%E5%92%8Cbcelosswithlogic/</guid>
      <description>损失函数BCELoss和BCELosswithlogic
参考了一下别人的资料，自己写了一下代码
 @TOC
1. 代码 &amp;#39;&amp;#39;&amp;#39; Date: 2021-07-03 17:36:14 LastEditors: Liuliang LastEditTime: 2021-07-03 17:51:05 Description: BCE_logic &amp;#39;&amp;#39;&amp;#39; import torch import torch.nn as nn from torch.random import seed import random SEED = 0 torch.manual_seed(SEED) # torch.cuda.manual_seed(SEED) input = torch.rand(3,3) sig = nn.Sigmoid() c = sig(input) # print(input) print(c) target = torch.FloatTensor([ [0,1,1], [0,0,1], [1,0,1] ]) print(target) loss = nn.BCELoss() val_loss = loss(c,target) print(val_loss) #验证BCEloss loss_2 = nn.BCEWithLogitsLoss() val_loss_2 = loss_2(input,target) print(val_loss_2) 2.</description>
    </item>
    
    <item>
      <title>32——torch.garther操作</title>
      <link>https://ioyy900205.github.io/post/2021-06-25-32torch.garther%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Fri, 25 Jun 2021 10:49:40 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-06-25-32torch.garther%E6%93%8D%E4%BD%9C/</guid>
      <description>在深度学习中有pytorch.garther操作。这里做一个简单解释
 @TOC
示例 &amp;#39;&amp;#39;&amp;#39; Date: 2021-06-25 10:40:56 LastEditors: Liuliang LastEditTime: 2021-06-25 10:46:39 Description: torch_garther &amp;#39;&amp;#39;&amp;#39; import torch b = torch.Tensor([[1,2,3],[4,5,6]]) print(b) index_1 = torch.LongTensor([[0,1],[2,0]]) print(index_1) index_2 = torch.LongTensor([[0,1,1],[0,0,0]]) print (torch.gather(b, dim=1, index=index_1)) # print torch.gather(b, dim=0, index=index_2) 结果
tensor([[1., 2., 3.], [4., 5., 6.]]) tensor([[0, 1], [2, 0]]) tensor([[1., 2.], [6., 4.]]) 很简单，第二个tensor相当于是一个索引。在第一个tensor上查找对应index的数值。输出在第三个tensor上。
例如，tensor_2 [0][0]位置的值是0
所以输出 找到tensor1的1
 参考资料</description>
    </item>
    
    <item>
      <title>31——装饰器python</title>
      <link>https://ioyy900205.github.io/post/2021-06-21-31%E8%A3%85%E9%A5%B0%E5%99%A8python/</link>
      <pubDate>Mon, 21 Jun 2021 12:00:10 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-06-21-31%E8%A3%85%E9%A5%B0%E5%99%A8python/</guid>
      <description>一个装饰器的例子，很方便理解
 @TOC
标题 先定义一个简单的函数foo
def foo(): print &amp;#39;call foo()&amp;#39; 现在我们想要计算次函数执行的时间，于是修改代码如下
import time def foo(): start = time.clock() print &amp;#39;call foo()&amp;#39; end = time.clock() print &amp;#39;using time:&amp;#39;,end - start 然后有一个更快的方法
import time def foo(): print &amp;#39;call foo()&amp;#39; def cal_time(func): start = time.clock() func() end =time.clock() print &amp;#39;using time:&amp;#39;, end - start cal_time(foo) 但是这样比较麻烦，如果foo换了，还得重新写其他的例如foo_1
import time def foo(): print &amp;#39;call foo()&amp;#39; # 定义一个计时器，传入一个函数，并返回另一个附加了计时功能的方法 def cal_time(func): # 定义一个内嵌的包装函数，给传入的函数加上计时功能的包装 def wrapper(): start = time.</description>
    </item>
    
    <item>
      <title>27——做计算机视觉还得懂LSTM</title>
      <link>https://ioyy900205.github.io/post/2021-06-09-27%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E8%BF%98%E5%BE%97%E6%87%82lstm/</link>
      <pubDate>Wed, 09 Jun 2021 12:14:22 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-06-09-27%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E8%BF%98%E5%BE%97%E6%87%82lstm/</guid>
      <description>Long Short-Term Memory Networks
LSTMs are a special kind of Recurrent Neural Network — capable of learning long-term dependencies by remembering information for long periods is the default behavior.
All recurrent neural networks are in the form of a chain of repeating modules of a neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.
  1. Step 1: Decide how much past data it should remember 2.</description>
    </item>
    
    <item>
      <title>26——GFNet源码解读</title>
      <link>https://ioyy900205.github.io/post/2021-06-07-26gfnet-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Mon, 07 Jun 2021 10:45:08 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-06-07-26gfnet-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/</guid>
      <description>26——GFNet源码解读
  标题  1. inference模块 1.1. initial 设置参数：数据集地址;checkpoint_path;eval_model
1.2. 载入模型部分 导入checkpoint,并读取数据
model_arch = checkpoint[&amp;#39;model_name&amp;#39;] patch_size = checkpoint[&amp;#39;patch_size&amp;#39;] prime_size = checkpoint[&amp;#39;patch_size&amp;#39;] flops = checkpoint[&amp;#39;flops&amp;#39;] model_flops = checkpoint[&amp;#39;model_flops&amp;#39;] policy_flops = checkpoint[&amp;#39;policy_flops&amp;#39;] fc_flops = checkpoint[&amp;#39;fc_flops&amp;#39;] anytime_classification = checkpoint[&amp;#39;anytime_classification&amp;#39;] budgeted_batch_classification = checkpoint[&amp;#39;budgeted_batch_classification&amp;#39;] dynamic_threshold = checkpoint[&amp;#39;dynamic_threshold&amp;#39;] maximum_length = len(checkpoint[&amp;#39;flops&amp;#39;]) model_configurations载入字典对应文件。
检查eval_model 并载入模型 (model and model_prime)
1.3. 载入数据集部分 traindir = args.data_url + &amp;#39;train/&amp;#39; valdir = args.data_url + &amp;#39;val/&amp;#39; normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.</description>
    </item>
    
    <item>
      <title>23-【pytorch Lightning】</title>
      <link>https://ioyy900205.github.io/post/2021-06-03-23pytorch-lightning/</link>
      <pubDate>Thu, 03 Jun 2021 15:13:20 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-06-03-23pytorch-lightning/</guid>
      <description>大部分的DL/ML代码都可以分为以下这三部分：
 研究代码 Research code (LightningModule ) 工程代码 Engineering code ( Trainer ) 非必要代码 Non-essential code ( Callbacks )   @TOC
研究代码  参考资料</description>
    </item>
    
    <item>
      <title>22——VSCode中plt.show()无法显示图片问题</title>
      <link>https://ioyy900205.github.io/post/2021-06-03-22vscode%E4%B8%ADplt.show%E6%97%A0%E6%B3%95%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87%E9%97%AE%E9%A2%98/</link>
      <pubDate>Thu, 03 Jun 2021 14:24:36 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-06-03-22vscode%E4%B8%ADplt.show%E6%97%A0%E6%B3%95%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87%E9%97%AE%E9%A2%98/</guid>
      <description>远程SSh时候，VSCode无法显示图片
  1. 解决方法  1. 解决方法 终端中输入：
export DISPLAY=:10.0  参考资料 https://www.pythonheidong.com/blog/article/714470/11e6dbde8921d93ae464/</description>
    </item>
    
    <item>
      <title>20——torch_view操作指南</title>
      <link>https://ioyy900205.github.io/post/2021-05-21-20torch_view%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97/</link>
      <pubDate>Fri, 21 May 2021 18:13:22 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-05-21-20torch_view%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97/</guid>
      <description>还是发现对view的操作不够深入，这里做了一个小demo。自行体会一下
  1. 代码 2. 结果 3. 理解  1. 代码 &amp;#39;&amp;#39;&amp;#39; Date: 2021-05-21 15:43:43 LastEditors: Liuliang LastEditTime: 2021-05-21 15:50:36 Description: view &amp;#39;&amp;#39;&amp;#39; import torch a = torch.arange(0,12,1) print(a) b = a.view(2,-1) print(b) c = b.view(6,2) print(c) 2. 结果 tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) tensor([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11]]) tensor([[ 0, 1], [ 2, 3], [ 4, 5], [ 6, 7], [ 8, 9], [10, 11]]) 3.</description>
    </item>
    
    <item>
      <title>19——avg_pool2d</title>
      <link>https://ioyy900205.github.io/post/2021-05-21-19avg_pool2d/</link>
      <pubDate>Fri, 21 May 2021 15:06:07 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-05-21-19avg_pool2d/</guid>
      <description>avg——pool2d理解
 @TOC
1. 直接上代码 import torch from torch.nn import functional as F # 1.初始化 input = torch.tensor( [ [1,1,1,1,1], [1,1,1,1,1], [0,0,0,1,1], [1,1,1,1,1] ]).unsqueeze(0).float() print(input.size())#torch.Size([1, 4, 5]) print(input) #2. avg_pool1d # m1 = F.avg_pool1d(input,kernel_size=2) # print(m1)#tensor([[[1.0000, 1.0000], # # [1.0000, 1.0000], # # [0.0000, 0.5000], # # [1.0000, 1.0000]]]) #3. avg_pool2d # m = F.avg_pool2d(input,kernel_size=2)#这里是在原矩阵中找出2*2的区域求平均，不够的舍弃，stride=(2,2) # print(m)#tensor([[[1.0000, 1.0000], # # [0.5000, 0.7500]]]) m3= F.avg_pool2d(input,kernel_size=2,stride=1)#这里是在原矩阵中找出2*2的区域求平均，不够的舍弃，stride=(1,1),[1,1,4,5]--&amp;gt;[1,1,3,4] print(m3)#tensor([[[1.0000, 1.0000, 1.0000, 1.0000], # [0.5000, 0.</description>
    </item>
    
    <item>
      <title>17——tqdm载入数据集测试</title>
      <link>https://ioyy900205.github.io/post/2021-05-20-17tqdm%E8%BD%BD%E5%85%A5%E6%95%B0%E6%8D%AE%E9%9B%86%E6%B5%8B%E8%AF%95/</link>
      <pubDate>Thu, 20 May 2021 16:50:49 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-05-20-17tqdm%E8%BD%BD%E5%85%A5%E6%95%B0%E6%8D%AE%E9%9B%86%E6%B5%8B%E8%AF%95/</guid>
      <description>代码已放在mess_around文件夹下
  1. 基本使用方式  1.1. list方式 1.2. 放一个迭代器在里面   2. 实例  2.1. 使用tqdm带来的效率损失  2.1.1. MNIST 2.1.2. ImageNet   2.2. num_workers的使用    1. 基本使用方式 1.1. list方式 （1）
for i in tqdm(range(10000)): #do something sleep(0.01) pass （2）
for char in tqdm([&amp;#34;a&amp;#34;, &amp;#34;b&amp;#34;, &amp;#34;c&amp;#34;, &amp;#34;d&amp;#34;]): #do something pass （3）
pbar = tqdm([&amp;#34;a&amp;#34;, &amp;#34;b&amp;#34;, &amp;#34;c&amp;#34;, &amp;#34;d&amp;#34;]) for char in pbar: sleep(1) pbar.set_description(&amp;#34;Processing %s&amp;#34; % char) 1.2. 放一个迭代器在里面 count = 0 for batch_idx, item in tqdm(enumerate(train_loader)): count+=batch_idx print(count) 这种方式是我使用的方式。简单来说就是把迭代器train_loader放在tqdm里面，这里增加了一个enumerate去增加一个序列。</description>
    </item>
    
    <item>
      <title>15——torch.tensor叶子节点</title>
      <link>https://ioyy900205.github.io/post/2021-05-19-15torch.tensor-%E5%8F%B6%E5%AD%90%E8%8A%82%E7%82%B9/</link>
      <pubDate>Wed, 19 May 2021 09:53:52 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-05-19-15torch.tensor-%E5%8F%B6%E5%AD%90%E8%8A%82%E7%82%B9/</guid>
      <description>讨论叶子节点
  1. 理顺逻辑  1.1. 元素 1.2. 计算    1. 理顺逻辑 1.1. 元素 在pytorch的计算图中，只有两种元素：
数据（tensor）
  叶子节点(leaf node)
  叶子节点可以理解成不依赖其他tensor的tensor。
  在pytorch中，神经网络层中的权值w的tensor均为叶子节点。
  自己定义的tensor例如a=torch.tensor([1.0])定义的节点是叶子节点。
  All Tensors that have requires_grad which is False will be leaf Tensors by convention.
  For Tensors that have requires_grad which is True, they will be leaf Tensors if they were created by the user. This means that they are not the result of an operation and so grad_fn is None.</description>
    </item>
    
    <item>
      <title>13————tensor内存占用计算实例</title>
      <link>https://ioyy900205.github.io/post/2021-05-17-13tensor%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E5%AE%9E%E4%BE%8B/</link>
      <pubDate>Mon, 17 May 2021 19:01:17 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-05-17-13tensor%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97%E5%AE%9E%E4%BE%8B/</guid>
      <description>网上查看了CSDN的代码，写的有误。所以这里写一个正确版本的
  ## 1. 各类型所占用的字节数 2. tensor内存计算 3. 清空内存  1. 各类型所占用的字节数  测试代码
import numpy as np import sys # 32位整型 ai32 = np.array([], dtype=np.int32) bi32 = np.arange(1, dtype=np.int32) ci32 = np.arange(5, dtype=np.int32) # 64位整型 ai64 = np.array([], dtype=np.int64) bi64 = np.arange(1, dtype=np.int64) ci64 = np.arange(5, dtype=np.int64) # 32位浮点数 af32 = np.array([], dtype=np.float32) bf32 = np.arange(1, dtype=np.float32) cf32 = np.arange(5, dtype=np.float32) # 64位浮点数 af64 = np.array([], dtype=np.float64) bf64 = np.</description>
    </item>
    
    <item>
      <title>08——数据集操作和图像处理——PyTorch</title>
      <link>https://ioyy900205.github.io/post/2021-05-11-voc2012%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%9B%BE%E7%89%87%E5%92%8Cbbox%E4%BF%A1%E6%81%AF%E6%98%BE%E7%A4%BA/</link>
      <pubDate>Tue, 11 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-05-11-voc2012%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%9B%BE%E7%89%87%E5%92%8Cbbox%E4%BF%A1%E6%81%AF%E6%98%BE%E7%A4%BA/</guid>
      <description>请不要假装很努力， 因为结果不会陪你演戏！
  1. 数据集读取 2. 转换函数 3. bbox画图  1. 数据集读取 from torch.utils.data import Dataset import os import torch import json from PIL import Image from lxml import etree class VOC2012DataSet(Dataset): &amp;#34;&amp;#34;&amp;#34;读取解析PASCAL VOC2012数据集&amp;#34;&amp;#34;&amp;#34; def __init__(self, voc_root, transforms, txt_name: str = &amp;#34;train.txt&amp;#34;): self.root = os.path.join(voc_root, &amp;#34;VOCdevkit&amp;#34;, &amp;#34;VOC2012&amp;#34;) self.img_root = os.path.join(self.root, &amp;#34;JPEGImages&amp;#34;) self.annotations_root = os.path.join(self.root, &amp;#34;Annotations&amp;#34;) # read train.txt or val.txt file txt_path = os.path.join(self.root, &amp;#34;ImageSets&amp;#34;, &amp;#34;Main&amp;#34;, txt_name) assert os.</description>
    </item>
    
    <item>
      <title>06——torch.cat维度操作——PyTorch</title>
      <link>https://ioyy900205.github.io/post/2021-05-10-torch.cat%E7%9A%84%E7%BB%B4%E5%BA%A6%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-05-10-torch.cat%E7%9A%84%E7%BB%B4%E5%BA%A6%E6%93%8D%E4%BD%9C/</guid>
      <description>请不要假装很努力， 因为结果不会陪你演戏！
  1. torch.cat  1.1. 二维数组  1.1.1. dim=0 1.1.2. dim=1   1.2. 三维数组  1.2.1. dim=0 1.2.2. dim=1 1.2.3. dim=2     2. 小结  1. torch.cat 1.1. 二维数组 1.1.1. dim=0 运行
import torch A = torch.ones(2,3) #2x3的张量（矩阵）  print(&amp;#34;A:&amp;#34;,A) B=2*torch.ones(4,3) #4x3的张量（矩阵）  print(&amp;#34;B:&amp;#34;,B) C=torch.cat((A,B),0)#按维数0（行）拼接 print(&amp;#34;C:&amp;#34;,C) print(C.size()) 结果
A: tensor([[1., 1., 1.], [1., 1., 1.]]) B: tensor([[2., 2., 2.], [2., 2., 2.], [2.</description>
    </item>
    
    <item>
      <title>07——torch.stack维度操作——PyTorch</title>
      <link>https://ioyy900205.github.io/post/2021-05-10-torch.stack%E7%9A%84%E7%BB%B4%E5%BA%A6%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-05-10-torch.stack%E7%9A%84%E7%BB%B4%E5%BA%A6%E6%93%8D%E4%BD%9C/</guid>
      <description>请不要假装很努力， 因为结果不会陪你演戏！
  1. 初始化 2. torch.stak  2.1. dim = 0 2.2. dim = 1 2.3. dim = 2    1. 初始化 input
import torch import numpy as np # 创建3*3的矩阵，a、b a=np.array([[1,2,3],[4,5,6],[7,8,9]]) b=np.array([[10,20,30],[40,50,60],[70,80,90]]) # 将矩阵转化为Tensor a = torch.from_numpy(a) b = torch.from_numpy(b) # 打印a、b、c print(a,a.size()) print(b,b.size()) output
tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) torch.Size([3, 3]) tensor([[10, 20, 30], [40, 50, 60], [70, 80, 90]]) torch.</description>
    </item>
    
    <item>
      <title>03——nn.module学习——PyTorch</title>
      <link>https://ioyy900205.github.io/post/2021-04-27-nn.module/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-04-27-nn.module/</guid>
      <description>请不要假装很努力， 因为结果不会陪你演戏！
  1. nn.moduel初步  1.1. Linear类 1.2. Conv2d类 1.3. 自定义层的步骤   2. 自定义层  2.1. 定义一个自定义层MyLayer 2.2. 自定义模型并且训练    1. nn.moduel初步 keras更加注重的是层Layer、pytorch更加注重的是模型Module。
1.1. Linear类 import math import torch from torch.nn.parameter import Parameter from .. import functional as F from .. import init from .module import Module from ..._jit_internal import weak_module, weak_script_method class Linear(Module): __constants__ = [&amp;#39;bias&amp;#39;] def __init__(self, in_features, out_features, bias=True): super(Linear, self).__init__() self.</description>
    </item>
    
  </channel>
</rss>
