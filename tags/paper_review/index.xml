<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paper_Review on 亮的笔记</title>
    <link>https://ioyy900205.github.io/tags/paper_review/</link>
    <description>Recent content in Paper_Review on 亮的笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 31 May 2021 10:41:41 +0800</lastBuildDate><atom:link href="https://ioyy900205.github.io/tags/paper_review/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>【现场分享】智源大会类脑视觉</title>
      <link>https://ioyy900205.github.io/post/2021-05-31-%E7%8E%B0%E5%9C%BA%E5%88%86%E4%BA%AB%E6%99%BA%E6%BA%90%E5%A4%A7%E4%BC%9A%E7%B1%BB%E8%84%91%E8%A7%86%E8%A7%89/</link>
      <pubDate>Mon, 31 May 2021 10:41:41 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-05-31-%E7%8E%B0%E5%9C%BA%E5%88%86%E4%BA%AB%E6%99%BA%E6%BA%90%E5%A4%A7%E4%BC%9A%E7%B1%BB%E8%84%91%E8%A7%86%E8%A7%89/</guid>
      <description>【现场分享】智源大会类脑视觉
 @TOC
标题 黄铁军
唐华锦
张兆翔
王威
类脑 拓展马尔视觉计算原理
研究内容 计算 成像 应用
 参考资料</description>
    </item>
    
    <item>
      <title>21——MSDNet论文的推理模块</title>
      <link>https://ioyy900205.github.io/post/2021-05-22-21msdnet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sat, 22 May 2021 10:21:24 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-05-22-21msdnet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</guid>
      <description>本文的核心主旨在于：在计算资源限制下对不同的图像进行不同的处理，可以理解成对于简单样本采用简单的方式处理，对于复杂样本则尽可能给其分配资源，以避免不必要的资源浪费节省计算量，并且在这种推理的思想上要实现网络对数据的自动适应。所以本文设计了一个新颖的二维多尺度网络结构，根据不同的资源需求训练了多个分类器，为了最大程度地重用分类器之间的计算，我们将它们作为早期出口并入单个深度卷积神经网络，并通过密集连接将它们互连，该构架在整个网络中同时保持粗略和精细的scale，获得了良好的效果。
  1. model 2. 推理部分  2.1. 实时推理方法 2.2. 出口分配   3. 讨论  1. model 这里有两个基本模块，一个是第一层的横向传播模块，一个是下采样加横向传播模块。
2. 推理部分 2.1. 实时推理方法 其实就是将每个出口的结果打印出来。
只不过在推理过程中，考虑了载入数据的时间（大约0.45s），整个batch的推理时间大约是0.6-0.7s&amp;rsquo;s之间。
程序在最后的地方对每个出口进行了输出
 prec@1 56.632 prec@5 79.942 prec@1 65.136 prec@5 86.252 prec@1 68.420 prec@5 88.632 prec@1 69.770 prec@5 89.418 prec@1 71.336 prec@5 90.364   之前有统计过计算量的地方，所以这里结合计算量就可以得到论文的结果。
2.2. 出口分配 这种方式对5个出口进行了样本数量设定（这里设置了40组）。进而可以学习到每个出口的threshold，从而实现了不同出口的退出机制。
3. 讨论 每个出口样本数量设定 是一个超参数。MSDNet所得到的结果目前来看不一定是最好的。
以下有收获：
 多尺度架构的编程方法。 网络模型参数和计算量的计算。 退出机制的学习方法。   参考资料
手动debug</description>
    </item>
    
    <item>
      <title>12————阅读论文记录</title>
      <link>https://ioyy900205.github.io/post/2021-05-14-12%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87%E9%93%BE%E6%8E%A5/</link>
      <pubDate>Fri, 14 May 2021 15:20:41 +0800</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-05-14-12%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87%E9%93%BE%E6%8E%A5/</guid>
      <description>阅读论文记录
  1. 图像分类(Classification) 2. 目标检测(Object Detection) 3. 目标分割(Segmentation) 4. Others 5. 动态神经网络   参考资料
 1. 图像分类(Classification)  AlexNet http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf ZFNet(Visualizing and Understanding Convolutional Networks) https://arxiv.org/abs/1311.2901 VGG https://arxiv.org/abs/1409.1556 GoogLeNet, Inceptionv1(Going deeper with convolutions) https://arxiv.org/abs/1409.4842 Batch Normalization https://arxiv.org/abs/1502.03167 Inceptionv3(Rethinking the Inception Architecture for Computer Vision) https://arxiv.org/abs/1512.00567 Inceptionv4, Inception-ResNet https://arxiv.org/abs/1602.07261 Xception(Deep Learning with Depthwise Separable Convolutions) https://arxiv.org/abs/1610.02357 ResNet https://arxiv.org/abs/1512.03385 ResNeXt https://arxiv.org/abs/1611.05431 DenseNet https://arxiv.org/abs/1608.06993 NASNet-A(Learning Transferable Architectures for Scalable Image Recognition) https://arxiv.</description>
    </item>
    
    <item>
      <title>审稿学习系列01——图像质量评估</title>
      <link>https://ioyy900205.github.io/post/2021-05-10-%E5%AE%A1%E7%A8%BF%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%9701/</link>
      <pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ioyy900205.github.io/post/2021-05-10-%E5%AE%A1%E7%A8%BF%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%9701/</guid>
      <description>审稿学习系列01——图像质量评估 LIU Liang
  1. 背景 2. 图像质量评估（Image Quality Assessment, IQA）——方法分类  2.1. 主观方法 2.2. 客观方法   3. 图像质量评估（Image Quality Assessment, IQA）——图像提供信息分类  3.1. 全参考(Full Reference-IQA, FR-IQA) 3.2. 半参考(Reduced Reference-IQA, RR-IQA) 3.3. 无参考(No Reference-IQA, NR-IQA)   4. 数据集 5. 评估方法  5.1. 评估指标   6. 结果  1. 背景 质量评估(Quality Assessment，QA)在许多领域有其广泛的实用性。（比如图像压缩、视频编解码、视频监控等。）
并且对高效、可靠质量评估的需求日益增加，所以QA成为一个感兴趣的研究领域。
每年都涌现出大量的新的QA算法，有些是扩展已有的算法，也有一些是QA算法的应用。
质量评估可分为：
  图像质量评估（Image Quality Assessment, IQA）
  视频质量评估（Video Quality Assessment, VQA）</description>
    </item>
    
  </channel>
</rss>
