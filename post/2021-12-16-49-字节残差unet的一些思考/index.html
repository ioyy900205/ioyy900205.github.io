<!doctype html>
<html lang="en-us">
  <head>
    <title>49-字节残差unet的思考 // 亮的笔记</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.101.0" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Liu Liang" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://ioyy900205.github.io/css/main.min.4a7ec8660f9a44b08c4da97c5f2e31b1192df1d4d0322e65c0dbbc6ecb1b863f.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="49-字节残差unet的思考"/>
<meta name="twitter:description" content="1. 无需LSTM结构 2. 无需将网络的 freq_bins 维度压缩至1. 3. 数据归一化的方式 4. 在融合了之后还进行了信息整理 5. 将频带切分 堆叠 送入网络 6. 优化目标 7. 关于Mask 1. 无需LSTM结构 中间做信息处理的部分是block7a-block7d
每个block都有4个残差conv块
每个残差conv块有2层卷积
(x_center, _) = self.conv_block7a(x6_pool) # (bs, 384, T / 32, F / 64) (x_center, _) = self.conv_block7b(x_center) # (bs, 384, T / 32, F / 64) (x_center, _) = self.conv_block7c(x_center) # (bs, 384, T / 32, F / 64) (x_center, _) = self.conv_block7d(x_center) # (bs, 384, T / 32, F / 64) 2."/>

    <meta property="og:title" content="49-字节残差unet的思考" />
<meta property="og:description" content="1. 无需LSTM结构 2. 无需将网络的 freq_bins 维度压缩至1. 3. 数据归一化的方式 4. 在融合了之后还进行了信息整理 5. 将频带切分 堆叠 送入网络 6. 优化目标 7. 关于Mask 1. 无需LSTM结构 中间做信息处理的部分是block7a-block7d
每个block都有4个残差conv块
每个残差conv块有2层卷积
(x_center, _) = self.conv_block7a(x6_pool) # (bs, 384, T / 32, F / 64) (x_center, _) = self.conv_block7b(x_center) # (bs, 384, T / 32, F / 64) (x_center, _) = self.conv_block7c(x_center) # (bs, 384, T / 32, F / 64) (x_center, _) = self.conv_block7d(x_center) # (bs, 384, T / 32, F / 64) 2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ioyy900205.github.io/post/2021-12-16-49-%E5%AD%97%E8%8A%82%E6%AE%8B%E5%B7%AEunet%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-12-16T16:03:44+08:00" />
<meta property="article:modified_time" content="2021-12-16T16:03:44+08:00" />



  </head>
  <body>
    <header class="app-header">
      <a href="https://ioyy900205.github.io"><img class="app-header-avatar" src="https://www.qqtouxiang.com/d/file/tupian/mx/20170926/jixq0zs051pwa.jpg" alt="Liu Liang" /></a>
      <h1>亮的笔记</h1>
      <nav class="app-header-menu">
          <a class="app-header-menu-item" href="/">Home</a>
             - 
          
          <a class="app-header-menu-item" href="/tags/">Tags</a>
             - 
          
          <a class="app-header-menu-item" href="/about/">About</a>
      </nav>
      <p>深度学习笔记本</p>
      <div class="app-header-social">
        
          <a href="https://github.com/ioyy900205" target="_blank" rel="noreferrer noopener">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>Github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg>
          </a>
        
          <a href="https://twitter.com/ioyy900205" target="_blank" rel="noreferrer noopener">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-twitter">
  <title>Twitter</title>
  <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path>
</svg>
          </a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">49-字节残差unet的思考</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Dec 16, 2021
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          3 min read
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <title>tag</title>
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7.01" y2="7"></line>
</svg>
              <a class="tag" href="https://ioyy900205.github.io/tags/pytorch/">PyTorch</a>
        </div>
      </div>
    </header>
    <div class="post-content">
      <hr>
<ul>
<li><a href="#1-%E6%97%A0%E9%9C%80lstm%E7%BB%93%E6%9E%84">1. 无需LSTM结构</a></li>
<li><a href="#2-%E6%97%A0%E9%9C%80%E5%B0%86%E7%BD%91%E7%BB%9C%E7%9A%84-freq_bins-%E7%BB%B4%E5%BA%A6%E5%8E%8B%E7%BC%A9%E8%87%B31">2. 无需将网络的 freq_bins 维度压缩至1.</a></li>
<li><a href="#3-%E6%95%B0%E6%8D%AE%E5%BD%92%E4%B8%80%E5%8C%96%E7%9A%84%E6%96%B9%E5%BC%8F">3. 数据归一化的方式</a></li>
<li><a href="#4-%E5%9C%A8%E8%9E%8D%E5%90%88%E4%BA%86%E4%B9%8B%E5%90%8E%E8%BF%98%E8%BF%9B%E8%A1%8C%E4%BA%86%E4%BF%A1%E6%81%AF%E6%95%B4%E7%90%86">4. 在融合了之后还进行了信息整理</a></li>
<li><a href="#5-%E5%B0%86%E9%A2%91%E5%B8%A6%E5%88%87%E5%88%86-%E5%A0%86%E5%8F%A0-%E9%80%81%E5%85%A5%E7%BD%91%E7%BB%9C">5. 将频带切分 堆叠 送入网络</a></li>
<li><a href="#6-%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87">6. 优化目标</a></li>
<li><a href="#7-%E5%85%B3%E4%BA%8Emask">7. 关于Mask</a></li>
</ul>
<h2 id="1-无需lstm结构">1. 无需LSTM结构</h2>
<p>中间做信息处理的部分是block7a-block7d</p>
<p>每个block都有4个残差conv块</p>
<p>每个残差conv块有2层卷积</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>        (x_center, _) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv_block7a(x6_pool)  <span style="color:#75715e"># (bs, 384, T / 32, F / 64)</span>
</span></span><span style="display:flex;"><span>        (x_center, _) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv_block7b(x_center)  <span style="color:#75715e"># (bs, 384, T / 32, F / 64)</span>
</span></span><span style="display:flex;"><span>        (x_center, _) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv_block7c(x_center)  <span style="color:#75715e"># (bs, 384, T / 32, F / 64)</span>
</span></span><span style="display:flex;"><span>        (x_center, _) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv_block7d(x_center)  <span style="color:#75715e"># (bs, 384, T / 32, F / 64)</span>
</span></span></code></pre></div><h2 id="2-无需将网络的-freq_bins-维度压缩至1">2. 无需将网络的 freq_bins 维度压缩至1.</h2>
<p>重点考虑的是下采样了多少倍 代码是64倍  2**6 6层block</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>        (x1_pool, x1) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encoder_block1(x)  <span style="color:#75715e"># x1_pool: (bs, 32, T / 2, F / 2)</span>
</span></span><span style="display:flex;"><span>        (x2_pool, x2) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encoder_block2(x1_pool)  <span style="color:#75715e"># x2_pool: (bs, 64, T / 4, F / 4)</span>
</span></span><span style="display:flex;"><span>        (x3_pool, x3) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encoder_block3(x2_pool)  <span style="color:#75715e"># x3_pool: (bs, 128, T / 8, F / 8)</span>
</span></span><span style="display:flex;"><span>        (x4_pool, x4) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encoder_block4(
</span></span><span style="display:flex;"><span>            x3_pool
</span></span><span style="display:flex;"><span>        )  <span style="color:#75715e"># x4_pool: (bs, 256, T / 16, F / 16)</span>
</span></span><span style="display:flex;"><span>        (x5_pool, x5) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encoder_block5(
</span></span><span style="display:flex;"><span>            x4_pool
</span></span><span style="display:flex;"><span>        )  <span style="color:#75715e"># x5_pool: (bs, 384, T / 32, F / 32)</span>
</span></span><span style="display:flex;"><span>        (x6_pool, x6) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encoder_block6(
</span></span><span style="display:flex;"><span>            x5_pool
</span></span><span style="display:flex;"><span>        )  <span style="color:#75715e"># x6_pool: (bs, 384, T / 32, F / 64)</span>
</span></span></code></pre></div><h2 id="3-数据归一化的方式">3. 数据归一化的方式</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> mag<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>bn0(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;(batch_size, input_channels, time_steps, freq_bins)&#34;&#34;&#34;</span>
</span></span></code></pre></div><h2 id="4-在融合了之后还进行了信息整理">4. 在融合了之后还进行了信息整理</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>        x12 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>decoder_block6(x11, x1)  <span style="color:#75715e"># (bs, 32, T, F)</span>
</span></span><span style="display:flex;"><span>        (x, _) <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>after_conv_block1(x12)  <span style="color:#75715e"># (bs, 32, T, F)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>after_conv2(x)  <span style="color:#75715e"># (bs, channels * 3, T, F)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># (batch_size, input_channles * subbands_num * targets_num * k, T, F&#39;)</span>
</span></span></code></pre></div><h2 id="5-将频带切分-堆叠-送入网络">5. 将频带切分 堆叠 送入网络</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>subband<span style="color:#f92672">.</span>analysis(x)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># (bs, input_channels, T, F&#39;), where F&#39; = F // subbands_num</span>
</span></span></code></pre></div><h2 id="6-优化目标">6. 优化目标</h2>
<p>传给损失函数的参数有：</p>
<ol>
<li>处理过后的output</li>
<li>target音源</li>
<li>mixture音源</li>
</ol>
<p>损失函数是一种联合损失函数：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>        <span style="color:#75715e"># L1 loss in the time-domain.</span>
</span></span><span style="display:flex;"><span>        wav_loss <span style="color:#f92672">=</span> l1_wav(output, target)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># L1 loss on the spectrogram.</span>
</span></span><span style="display:flex;"><span>        sp_loss <span style="color:#f92672">=</span> l1(
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>wav_to_spectrogram(output, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-8</span>),
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>wav_to_spectrogram(target, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-8</span>),
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># sp_loss /= math.sqrt(self.window_size)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># sp_loss *= 1.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Total loss.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> wav_loss <span style="color:#f92672">+</span> sp_loss
</span></span></code></pre></div><h2 id="7-关于mask">7. 关于Mask</h2>
<p>从pytorch_lightning文件上面来看，感觉是直接输出需要的语音，没有mask的结构</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">training_step</span>(self, batch_data_dict: Dict, batch_idx: int) <span style="color:#f92672">-&gt;</span> torch<span style="color:#f92672">.</span>float:
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;&#34;&#34;Forward a mini-batch data to model, calculate loss function, and
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        train for one step. A mini-batch data is evenly distributed to multiple
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        devices (if there are) for parallel training.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            batch_data_dict: e.g. {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#39;vocals&#39;: (batch_size, channels_num, segment_samples),
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#39;accompaniment&#39;: (batch_size, channels_num, segment_samples),
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#39;mixture&#39;: (batch_size, channels_num, segment_samples)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            batch_idx: int
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            loss: float, loss function of this mini-batch
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        input_dict, target_dict <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>batch_data_preprocessor(batch_data_dict)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># input_dict: {</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     &#39;waveform&#39;: (batch_size, channels_num, segment_samples),</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     (if_exist) &#39;condition&#39;: (batch_size, channels_num),</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># }</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># target_dict: {</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     &#39;waveform&#39;: (batch_size, target_sources_num * channels_num, segment_samples),</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># }</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Forward.</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        output_dict <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model(input_dict)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># output_dict: {</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#     &#39;waveform&#39;: (batch_size, target_sources_num * channels_num, segment_samples),</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># }</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        outputs <span style="color:#f92672">=</span> output_dict[<span style="color:#e6db74">&#39;waveform&#39;</span>]
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># outputs:, e.g, (batch_size, target_sources_num * channels_num, segment_samples)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Calculate loss.</span>
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>loss_function(
</span></span><span style="display:flex;"><span>            output<span style="color:#f92672">=</span>outputs,
</span></span><span style="display:flex;"><span>            target<span style="color:#f92672">=</span>target_dict[<span style="color:#e6db74">&#39;waveform&#39;</span>],
</span></span><span style="display:flex;"><span>            mixture<span style="color:#f92672">=</span>input_dict[<span style="color:#e6db74">&#39;waveform&#39;</span>],
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> loss
</span></span></code></pre></div><p>也许简单有效才是王道。92fork 668star表明这个网络应该是不错的。</p>
<hr>
<p><strong>参考资料</strong></p>
<p><a href="https://github.com/bytedance/music_source_separation">https://github.com/bytedance/music_source_separation</a></p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
