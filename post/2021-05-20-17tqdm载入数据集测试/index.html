<!doctype html>
<html lang="en-us">
  <head>
    <title>17——tqdm载入数据集测试 // 亮的笔记</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.90.1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Liu Liang" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://ioyy900205.github.io/css/main.min.88e7083eff65effb7485b6e6f38d10afbec25093a6fac42d734ce9024d3defbd.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="17——tqdm载入数据集测试"/>
<meta name="twitter:description" content="代码已放在mess_around文件夹下
  1. 基本使用方式  1.1. list方式 1.2. 放一个迭代器在里面   2. 实例  2.1. 使用tqdm带来的效率损失  2.1.1. MNIST 2.1.2. ImageNet   2.2. num_workers的使用    1. 基本使用方式 1.1. list方式 （1）
for i in tqdm(range(10000)): #do something sleep(0.01) pass （2）
for char in tqdm([&#34;a&#34;, &#34;b&#34;, &#34;c&#34;, &#34;d&#34;]): #do something pass （3）
pbar = tqdm([&#34;a&#34;, &#34;b&#34;, &#34;c&#34;, &#34;d&#34;]) for char in pbar: sleep(1) pbar.set_description(&#34;Processing %s&#34; % char) 1.2. 放一个迭代器在里面 count = 0 for batch_idx, item in tqdm(enumerate(train_loader)): count&#43;=batch_idx print(count) 这种方式是我使用的方式。简单来说就是把迭代器train_loader放在tqdm里面，这里增加了一个enumerate去增加一个序列。"/>

    <meta property="og:title" content="17——tqdm载入数据集测试" />
<meta property="og:description" content="代码已放在mess_around文件夹下
  1. 基本使用方式  1.1. list方式 1.2. 放一个迭代器在里面   2. 实例  2.1. 使用tqdm带来的效率损失  2.1.1. MNIST 2.1.2. ImageNet   2.2. num_workers的使用    1. 基本使用方式 1.1. list方式 （1）
for i in tqdm(range(10000)): #do something sleep(0.01) pass （2）
for char in tqdm([&#34;a&#34;, &#34;b&#34;, &#34;c&#34;, &#34;d&#34;]): #do something pass （3）
pbar = tqdm([&#34;a&#34;, &#34;b&#34;, &#34;c&#34;, &#34;d&#34;]) for char in pbar: sleep(1) pbar.set_description(&#34;Processing %s&#34; % char) 1.2. 放一个迭代器在里面 count = 0 for batch_idx, item in tqdm(enumerate(train_loader)): count&#43;=batch_idx print(count) 这种方式是我使用的方式。简单来说就是把迭代器train_loader放在tqdm里面，这里增加了一个enumerate去增加一个序列。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ioyy900205.github.io/post/2021-05-20-17tqdm%E8%BD%BD%E5%85%A5%E6%95%B0%E6%8D%AE%E9%9B%86%E6%B5%8B%E8%AF%95/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-05-20T16:50:49+08:00" />
<meta property="article:modified_time" content="2021-05-20T16:50:49+08:00" />



  </head>
  <body>
    <header class="app-header">
      <a href="https://ioyy900205.github.io"><img class="app-header-avatar" src="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=3520060145,2875461924&amp;fm=26&amp;gp=0.jpg" alt="Liu Liang" /></a>
      <h1>亮的笔记</h1>
      <nav class="app-header-menu">
          <a class="app-header-menu-item" href="/">Home</a>
             - 
          
          <a class="app-header-menu-item" href="/tags/">Tags</a>
             - 
          
          <a class="app-header-menu-item" href="/about/">About</a>
      </nav>
      <p>深度学习笔记本</p>
      <div class="app-header-social">
        
          <a href="https://github.com/ioyy900205" target="_blank" rel="noreferrer noopener">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>Github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg>
          </a>
        
          <a href="https://twitter.com/ioyy900205" target="_blank" rel="noreferrer noopener">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-twitter">
  <title>Twitter</title>
  <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path>
</svg>
          </a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">17——tqdm载入数据集测试</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          May 20, 2021
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          2 min read
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <title>tag</title>
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7.01" y2="7"></line>
</svg>
              <a class="tag" href="https://ioyy900205.github.io/tags/pytorch/">PyTorch</a>
        </div>
      </div>
    </header>
    <div class="post-content">
      <p>代码已放在mess_around文件夹下</p>
<hr>
<ul>
<li><a href="#1-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F">1. 基本使用方式</a>
<ul>
<li><a href="#11-list%E6%96%B9%E5%BC%8F">1.1. list方式</a></li>
<li><a href="#12-%E6%94%BE%E4%B8%80%E4%B8%AA%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%9C%A8%E9%87%8C%E9%9D%A2">1.2. 放一个迭代器在里面</a></li>
</ul>
</li>
<li><a href="#2-%E5%AE%9E%E4%BE%8B">2. 实例</a>
<ul>
<li><a href="#21-%E4%BD%BF%E7%94%A8tqdm%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%95%88%E7%8E%87%E6%8D%9F%E5%A4%B1">2.1. 使用tqdm带来的效率损失</a>
<ul>
<li><a href="#211-mnist">2.1.1. MNIST</a></li>
<li><a href="#212-imagenet">2.1.2. ImageNet</a></li>
</ul>
</li>
<li><a href="#22-num_workers%E7%9A%84%E4%BD%BF%E7%94%A8">2.2. num_workers的使用</a></li>
</ul>
</li>
</ul>
<h2 id="1-基本使用方式">1. 基本使用方式</h2>
<h3 id="11-list方式">1.1. list方式</h3>
<p>（1）</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> tqdm(range(<span style="color:#ae81ff">10000</span>)):  
     <span style="color:#75715e">#do something</span>
     sleep(<span style="color:#ae81ff">0.01</span>)
     <span style="color:#66d9ef">pass</span>
</code></pre></div><p>（2）</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">for</span> char <span style="color:#f92672">in</span> tqdm([<span style="color:#e6db74">&#34;a&#34;</span>, <span style="color:#e6db74">&#34;b&#34;</span>, <span style="color:#e6db74">&#34;c&#34;</span>, <span style="color:#e6db74">&#34;d&#34;</span>]):
    <span style="color:#75715e">#do something</span>
    <span style="color:#66d9ef">pass</span>
</code></pre></div><p>（3）</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">pbar <span style="color:#f92672">=</span> tqdm([<span style="color:#e6db74">&#34;a&#34;</span>, <span style="color:#e6db74">&#34;b&#34;</span>, <span style="color:#e6db74">&#34;c&#34;</span>, <span style="color:#e6db74">&#34;d&#34;</span>])
<span style="color:#66d9ef">for</span> char <span style="color:#f92672">in</span> pbar:
    sleep(<span style="color:#ae81ff">1</span>)
    pbar<span style="color:#f92672">.</span>set_description(<span style="color:#e6db74">&#34;Processing </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> char)
</code></pre></div><h3 id="12-放一个迭代器在里面">1.2. 放一个迭代器在里面</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">count <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
<span style="color:#66d9ef">for</span> batch_idx, item <span style="color:#f92672">in</span> tqdm(enumerate(train_loader)):
    count<span style="color:#f92672">+=</span>batch_idx
print(count)
</code></pre></div><p>这种方式是我使用的方式。简单来说就是把迭代器train_loader放在tqdm里面，这里增加了一个enumerate去增加一个序列。</p>
<h2 id="2-实例">2. 实例</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> tqdm <span style="color:#f92672">import</span> tqdm
<span style="color:#f92672">import</span> torch
<span style="color:#f92672">from</span> my_dataset <span style="color:#f92672">import</span> CocoDetection
<span style="color:#f92672">import</span> torchvision.transforms <span style="color:#66d9ef">as</span> transforms
<span style="color:#f92672">import</span> torchvision
<span style="color:#f92672">import</span> torchvision.datasets <span style="color:#66d9ef">as</span> datasets
<span style="color:#f92672">from</span> time <span style="color:#f92672">import</span> sleep <span style="color:#66d9ef">as</span> sleep
<span style="color:#f92672">import</span> time
<span style="color:#f92672">import</span> os 

<span style="color:#75715e"># data_transform = {</span>
<span style="color:#75715e">#     &#34;train&#34;: transforms.Compose([transforms.ToTensor(),</span>
<span style="color:#75715e">#                                     transforms.RandomHorizontalFlip(0.5)]),</span>
<span style="color:#75715e">#     &#34;val&#34;: transforms.Compose([transforms.ToTensor()])</span>
<span style="color:#75715e"># }</span>
<span style="color:#75715e"># COCO_root = &#39;/media/data/data02/COCO2017&#39;</span>

<span style="color:#75715e"># train_data_set = CocoDetection(COCO_root, &#34;train&#34;, data_transform[&#34;train&#34;])</span>

<span style="color:#75715e"># train_loader = torch.utils.data.DataLoader(train_data_set,</span>
<span style="color:#75715e">#                                                     batch_size=32,</span>
<span style="color:#75715e">#                                                     shuffle=True,</span>
<span style="color:#75715e">#                                                     pin_memory=True,</span>
<span style="color:#75715e">#                                                     # num_workers=8,</span>
<span style="color:#75715e">#                                                     collate_fn=train_data_set.collate_fn)</span>
<span style="color:#75715e"># # i = 0</span>
<span style="color:#75715e"># imgs = 0</span>
<span style="color:#75715e"># target = 0</span>
<span style="color:#75715e"># trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])</span>

<span style="color:#75715e"># train_data_loader = torchvision.datasets.MNIST(</span>
<span style="color:#75715e">#     root= &#34;/home/liuliang/dataset_python/&#34;,</span>
<span style="color:#75715e">#     train=True,</span>
<span style="color:#75715e">#     transform=trans,</span>
<span style="color:#75715e">#     download=True) </span>

<span style="color:#75715e"># batch_size = 300</span>

traindir <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(<span style="color:#e6db74">&#39;/media/data/data02/Imagenet2012/&#39;</span>, <span style="color:#e6db74">&#39;train&#39;</span>)

normalize <span style="color:#f92672">=</span> transforms<span style="color:#f92672">.</span>Normalize(mean<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0.485</span>, <span style="color:#ae81ff">0.456</span>, <span style="color:#ae81ff">0.406</span>],
                                    std<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0.229</span>, <span style="color:#ae81ff">0.224</span>, <span style="color:#ae81ff">0.225</span>])

train_dataset <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>ImageFolder(
    traindir,
    transforms<span style="color:#f92672">.</span>Compose([
        transforms<span style="color:#f92672">.</span>RandomResizedCrop(<span style="color:#ae81ff">224</span>),
        transforms<span style="color:#f92672">.</span>RandomHorizontalFlip(),
        transforms<span style="color:#f92672">.</span>ToTensor(),
        normalize,
    ])
    )

train_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(
                 dataset<span style="color:#f92672">=</span>train_dataset,
                 batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>,
                 num_workers<span style="color:#f92672">=</span><span style="color:#ae81ff">16</span>,
                 shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
                 
a1 <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
<span style="color:#66d9ef">for</span> batch_idx, (x, target) <span style="color:#f92672">in</span> tqdm(enumerate(train_loader),total<span style="color:#f92672">=</span>len(train_loader)):
    <span style="color:#75715e"># print(batch_idx,x.size(),target.size())</span>
    <span style="color:#75715e"># input()</span>
    <span style="color:#66d9ef">pass</span>
a2 <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
print(a2<span style="color:#f92672">-</span>a1)


a1 <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
<span style="color:#66d9ef">for</span> batch_idx, (x, target) <span style="color:#f92672">in</span> enumerate(train_loader):
    <span style="color:#75715e"># print(batch_idx,x.size(),target.size())</span>
    <span style="color:#75715e"># input()</span>
    <span style="color:#66d9ef">pass</span>
a2 <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
print(a2<span style="color:#f92672">-</span>a1)

<span style="color:#75715e"># count = 0</span>
<span style="color:#75715e"># for batch_idx, item in tqdm(enumerate(train_loader)):</span>
<span style="color:#75715e">#     count+=batch_idx</span>
<span style="color:#75715e"># print(count)</span>


<span style="color:#75715e"># for data, target in tqdm(train_data_loader):</span>
<span style="color:#75715e">#     print(data)</span>
<span style="color:#75715e">#     pass</span>

<span style="color:#75715e">#用list方式.</span>

<span style="color:#75715e"># for i in tqdm(range(10000)):  </span>
<span style="color:#75715e">#      #do something</span>
<span style="color:#75715e">#      sleep(0.01)</span>
<span style="color:#75715e">#      pass</span>

<span style="color:#75715e"># for char in tqdm([&#34;a&#34;, &#34;b&#34;, &#34;c&#34;, &#34;d&#34;]):</span>
<span style="color:#75715e">#     #do something</span>
<span style="color:#75715e">#     pass</span>

<span style="color:#75715e"># pbar = tqdm([&#34;a&#34;, &#34;b&#34;, &#34;c&#34;, &#34;d&#34;])</span>
<span style="color:#75715e"># for char in pbar:</span>
<span style="color:#75715e">#     sleep(1)</span>
<span style="color:#75715e">#     pbar.set_description(&#34;Processing %s&#34; % char)</span>
</code></pre></div><p>以上的我的测试代码，读取的是imagenet数据集128万张图片做一个测试。</p>
<h3 id="21-使用tqdm带来的效率损失">2.1. 使用tqdm带来的效率损失</h3>
<p>在MNIST和Imagenet上都进行了测试。</p>
<h4 id="211-mnist">2.1.1. MNIST</h4>
<p>使用这个tqdm会增加1-2%的计算时间。</p>
<p><img src="https://github.com/ioyy900205/ioyy900205.github.io/raw/main/post/images/e0a62357a278305992242fb23f8c8efad8b531e2d54f14a72d815388ba77bd30.png" alt="图 1"></p>
<h4 id="212-imagenet">2.1.2. ImageNet</h4>
<pre><code>使用tqdm：1011s

不适用tqdm：1027s
</code></pre>
<h3 id="22-num_workers的使用">2.2. num_workers的使用</h3>
<p>对于大数据集num_workers很有用。如果不设置的化速度会非常慢
性能允许的情况下，数字越大，速度越快。</p>
<hr>
<p><strong>参考资料</strong></p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
